https://juejin.cn/post/6844904106461495303


![[Pasted image 20220726213731.png]]

如果锁的超时时间设置的太小，会导致任务还没执行完锁就过期，导致其他线程进入

# Redison
![[Pasted image 20220727205032.png]]
## 加锁
Redison锁在redis里的hash结构：
![[Pasted image 20220727205541.png]]
```xml
KEY[1]：锁名（wht）
ARGV[1]：超时时间（30s）
ARGV[2]：UUID:线程id
ARGV[3]：重入次数
```
加锁代码的逻辑是：如果名为why的key不存在，那么就创建这个hash结构（获取锁），如果这个结构里的<uuid：线程id>成员不存在，就创建这个成员并赋值为1，否则执行+1操作。

## 重入
在Redison中，每台机器只会生成一个UUID，同一机器的不同线程的线程id也不相同。

重入代码的逻辑是：如果名为why的key存在，并且这个hash结构里的<uuid：线程id>也存在，就说明是同一台机器的同一个线程，可以重入；而同一机器的不同线程由于线程id不同所以无法获取锁，不同机器由于UUID不同更无法获取锁。这就是<uuid：线程id>的精妙之处。

## 返回
如果锁存在，返回 KEY[1] 的剩余存活时间。

## 续命
![[Pasted image 20220727211548.png]]
这里的 ttlRemaining 就是经过 lua 脚本后返回的值。当加锁成功或者重入成功后会返回 null，进入这个方法：
![[Pasted image 20220727211656.png]]
①：这是一个定时任务。

②：这个定时任务需要执行的核心代码。

③：该任务每 internalLockLeaseTime/3ms 后执行一次。而 internalLockLeaseTime 默认为 30000。所以该任务每 10s 执行一次。

2的内容为：
![[Pasted image 20220727211740.png]]
先判断 UUID:threadId 是否存在，如果存在则把 key 的过期时间重新设置为 30s，这就是一次续命操作。

这个定时任务是netty里的时间轮：
![[Pasted image 20220727211949.png]]
![[Pasted image 20220727212004.png]]
它的工作原理如下：

图片中的时间轮大小为 8 格，每格又指向一个保存着待执行任务的链表。

我们假设它每 1s 转一格，当前位于第 0 格，现在要添加一个 5s 后执行的任务，则0+5=5，在第5格的链表中添加一个任务节点即可，同时标识该节点round=0。

我们假设它每 1s 转一格，当前位于第 0 格，现在要添加一个 17s 后执行的任务，则（0+17）% 8 = 1，则在第 1 格添加一个节点指向任务，并标记round=2，时间轮每经过第 1 格后，对应的链表中的任务的 round 都会减 1 。则当时间轮第 3 次经过第 1 格时，会执行该任务。

## 解锁
![[Pasted image 20220727212541.png]]
里面有个 counter 的判断，如果减一后小于等于 0。就执行 del key 的操作。而里面的publish就是通知别的线程来获取锁，这里是基于 redis 的发布/订阅功能。

之前加锁失败的线程会执行tryAcquire，利用java信号量sephem阻塞锁剩余时间。但是如果获取锁的线程很快就将锁释放了，而之前获取到的锁剩余时间是20s，难道要等20s才能重新获取锁吗？答案是否定的。因为在阻塞之前该线程还通过subscribe订阅了释放锁的channel，在锁释放后会执行回调，回调里会唤醒信号量，从而重新去获取锁：
![[Pasted image 20220727212623.png]]
![[Pasted image 20220727213704.png]]

接下来就只剩下一个问题没有解决了：**怎么让看门狗知道不用续命了？**
其实就是在执行完解锁的 lua 脚本之后，通过响应式编程，完成了 cancel 操作。
![[Pasted image 20220727212705.png]]

## 问题
![[Pasted image 20220727212849.png]]
分布式锁的一致性要求 CP，但是Redis 集群架构之间的异步通信满足的是 AP ，因此对不上呀，就是有问题的啊。

但是为什么 Redis 做分布式锁还是那么流行呢？

可能是因为大多场景中可以容忍它的这个问题，也可能是使用者存在侥幸心理吧，或者说使用者就当个黑盒使用，根本不知道可能会出问题。

https://juejin.cn/post/6844904106461495303
https://juejin.cn/post/6844904090703495181

redis只要主节点落盘成功就会返回成功吗？会等所有从节点落盘成功才返回吗？
zk会等半数以上从节点落盘成功才会返回成功，如果用zk做分布式锁，当主节点挂掉，一定会从半数以上的数据较多的从节点里选举主节点，就能避免redis做分布式锁的问题。
同理redis如果想解决这个问题，可以使用redlock，原理等同zk，加锁时必须等待半数以上节点成功才算成功，这样即使主节点挂掉，另一个线程想要获取已存在的锁，那么他无论如何也无法在半数以上的节点内设值成功，因为已经有半数以上的节点设置了之前的key。

但是redlock也有问题，如果每个redis节点也有从节点，那么当某个redis节点挂了，但他的从节点还没来得及同步数据，那么等他变为主节点后会丢失锁信息，导致其他获取锁的线程可以给半数以上节点设值。要想解决这个问题，可以不给主节点设置从节点，这样会使得如果半数以上节点挂了导致redis不可用，降低了可用性；或者增加主节点个数来降低半数以上节点挂了的可能性，但这样会降低加锁性能。
再或者redis持久化规则是每隔1s持久化一次，那么如果某次加锁还没持久化就挂掉，还是会丢失锁信息。
![[Pasted image 20220727222319.png]]

