# 数据库三范式
[[数据库范式]]

# MRR
即多范围读取优化，当对二级索引进行范围查找时，如 name>'0' and name <'z'，虽然二级索引是有序的，但是它关联的聚簇索引却是无序的，需要进行多次随机io的回表操作，增加了io开销。而MRR会先查一部分二级索引，在内存中将这部分二级索引关联的聚簇索引进行排序后，再集中进行一次顺序io的回表，大大增加了效率。
![[Pasted image 20220129222255.png]]

# InnoDB三大特性
## 1.双写缓冲区 
占系统表空间的两个区，即2MB。Mysql每次向系统写入一页（16KB）数据，但是操作系统每次向磁盘写入的数据是4KB，所以要写4次。中间只要有一次写入错误，这一页都会出错。

![[Pasted image 20220201233006.png]]

Mysql先将数据从BufferPool写入内存的DoublewriteBuffer，再从内存的DoublewriteBuffer向磁盘的DoublewriteBuffer写入，成功后再写入表空间。

Mysql异常关闭时，如果磁盘的DoublewriteBuffer写成功了，就用其中的数据来恢复表数据（整页恢复）；如果DoublewriteBuffer也写失败了，就用表空间的原始数据（如果是插入操作那就是插入前的数据，更新操作就是更新前的数据）结合redo log（重做日志）逐条恢复，这个效率很定低于从DoublewriteBuffer进行恢复。

## 2.自适应哈希索引
InnoDB存储引擎如果监控到某个索引经常用，那么就认为是热数据，然后内部自己创建一个hash索引，称之为自适应哈希索引，创建以后，如果下次又查询到这个索引，那么直接通过hash算法推导出记录的地址，直接一次就能查到数据，比重复去B+tree索引中查询三四次节点的效率高了不少。

InnoDB存储引擎使用的哈希函数采用除法散列方式，其冲突机制采用链表方式。注意，对于自适应哈希索引仅是数据库自身创建并使用的，我们并不能对其进行干预。通过命令show engine innodb status 可以看到当前自适应哈希索引的使用状况。

![[Pasted image 20220129232444.png]]

同时在MySQL 5.7中，自适应哈希索引搜索系统被分区。每个索引都绑定到一个特定的分区，每个分区都由一个单独的 latch 锁保护。

## 3.Buffer Pool
![[Pasted image 20220129210745.png]]
![[Pasted image 20220202003649.png]]

所有的增删改查都直接操作BufferPool，如果BufferPool中没有数据时，再从磁盘中读取。
磁盘数据被读到BufferPool后，在BufferPool中也是以页的方式进行组织，每页都有一个对应的控制块，控制块以链表的形式进行组织：
![[Pasted image 20220202000706.png]]
空闲的页对应的控制块连接成free链表，使用后从链表移除。
如果只是select，那么BufferPool中的数据和磁盘中的数据是一致的。但是如果有更新操作，那么BufferPool中的数据会与磁盘不一致，这些不一致的控制块连接成flush链表。

BufferPool也有缓存淘汰策略，即LRU。如果一个区（64个页）中有56个页被连续访问过，或者有13个页被随机访问过，那么mysql会将整个区预读进BufferPool。由于mysql会将对一个页里一条数据的访问视为对这个页的一次访问，所以全表扫描会使得大量的页的访问次数激增，从而导致缓存被更新，原本很热的区域被挤掉，而这种更新在业务上是不期望看到的。所以mysql在传统的LRU上进行了改进，将链表分为了yong（热区） 和 old（冷区）两部分（冷占37%），第一次加载的表会被放到old区的前面，而不会影响到yong区。但是仅仅这样还是无法避免全表扫描对热区的影响。所以mysql还会计算第一次和最后一次访问某个页的时间差，如果小于1s则被视为在全表扫描，仍然会被放在old区。

BufferPool中脏页向磁盘刷盘的时机：后台线程定时刷盘、BufferPool内存紧张。

线程安全问题：多实例（1-64个），每个大小是之前设置的size/设置的个数。官网推荐个数是，总大小/个数>=1G，但当总大小不足1G时，只能设置1个。

Redo Log的作用是：当Mysql宕机，BufferPool中没有刷盘的数据会从Redo Log中恢复。为什么BufferPool不直接同步刷盘？因为磁盘读取是随机操作，效率低，所以将刷盘动作设计成异步；同时同步向Redo Log中顺序写，防止数据丢失。顺序写的效率也远远高于随机写。

Redo Log和BinLog的二阶段提交和组提交详见[[redolog, undolog, binlog]]

默认128M，偏小，最好设置成60%的机器物理内存大小，官方推荐80%

change buffer：BufferPool是当对聚簇索引做修改时的优化，当对二级索引做了更改，会利用change buffer做优化

# 成本
## 查看成本计算结果
mysql决定最终会全表扫描还是走索引，或者决定走哪个索引，是通过成本计算得出的。

如何查看各个索引成本计算的结果呢：
```shell
SET optimizer_trace="enabled=on";
sql语句
SELECT * FROM information_schema.OPTIMIZER_TRACE\
```
就可以看到全表扫描，以及各索引的成本计算结果。

## 成本计算方式
I/O成本：1		CPU成本：0.2

对于一个sql：
```java
SELECT * FROM order_exp 
WHERE order_no IN ('DD00_6S', 'DD00_9S','DD00_10S') 
AND expire_time> '2021-03-22 18:28:28' 
AND expire_time<='2021-03-22 18:35:09' 
AND insert_time> expire_time 
AND order_note LIKE '%7排1%' 
AND order_status = 0;
```
索引有：idx_order_no、idx_expire_time

全表扫描成本：I/O成本+CPU成本=
页面数(表大小/16k) \* 1.0+1.1(微调数)+表记录数 \* 0.2+1.0(微调数)

二级索引成本：I/O成本+CPU成本+回表I/O成本+回表CPU成本
范围数(查了几个区间就视为查了几页) \* 1.0+范围内记录数 \* 0.2+范围内记录数(有几条记录就视为回了几次表) \* 1.0+范围内记录数 \* 0.2

### index dive
对于expire_time，在计算成本时，由于其在查询时连续，视为只查了一个区间，即查了一页，需要一次I/O；而对于order_no，像in这种可能会包含多个单点区间的查询，I/O次数很清楚是3 \* 1.0。
但当计算回表I/O次数时，需要知道所有区间包含的记录数。在单点区间数量低于某个阈值时（show variables like '%dive%'，5.7以后是200），mysql会精确得在索引树中查找in中所有单点区间包含的记录总数（先在第二层索引中定位到某个单点区间的左右端，再计算这两端中间的记录数），视为对应的回表I/O次数，这种精确查找方法称为index dive；当大于200时，比如20000，mysql会使用这个索引的 记录数/索引的区分度(不重复的个数，可以用show index from order_exp查看) \* 区间个数(20000) 来估算in中的记录在索引中出现的次数。

![[Pasted image 20220131021956.png]]
![[Pasted image 20220131022012.png]]

查看某个sql的成本：explain format=json+sql

## 连接查询的成本

连接查询总成本 = 单次访问驱动表的成本 + 驱动表扇出数 x 单次访问被驱动表的成本

```java
SELECT * FROM order_exp AS s1 INNER JOIN order_exp2 AS s2 
ON s1.order_no=s2.order_note
WHERE s1.expire_time> '2021-03-22 18:28:28' 
AND s1.expire_time<= '2021-03-22 18:35:09' 
AND s2.expire_time> '2021-03-22 18:35:09' 
AND s2.expire_time<= '2021-03-22 18:35:59'
```
驱动表需要考虑expire_time是否有对应的索引，被驱动表需要考虑order_no和expire_time是否有对应的索引。对于被驱动表，order_note虽然是个常数，但并没有确切的值，它的成本计算可以使用前面说过的索引统计方法（就是索引列平均一个值重复多少次），并且前者是ref级别的查询，后者是range级别的查询，ref的访问方式要比range成本更低，优先选择走前者的索引。

所以对连接查询优化重点其实是下边这两个部分：尽量减少驱动表的扇出、对被驱动表的访问成本尽量低。

# 索引合并
一般情况下mysql在一次查询中只会用到单个二级索引，特殊情况下会用到多个，称为索引合并。

## 交集合并
前提：
1. 二级索引必须是等值查询
2. 主键索引可以是范围查询
```shell
select * from table where name='a' and address='b'

select * from table where id<10 and name='a'
```
当二级索引的多个等值查询会分别查出过多结果时，比起先通过一个条件的结果回表查出结果集，再从结果集中过滤剩余条件，mysql会先在二级索引树中求出所有等值查询结果的id（主键索引）的交集，从而得出更小的结果集，再去回表。

## 并集合并
前提：
1. 二级索引必须是等值查询
2. 主键索引可以是范围查询
3. 搜索条件的部分使用交集合并得到的集合，与其他方式得到的集合，取并集
```shell
select * from table where sex=1 or (name='a' and address='b')
```
(name='a' and address='b')使用交集合并的结果，与sex=1进行并集合并，最后进行回表。

## 排序并集合并
并集合并要求是等值查询，当不是等值查询时，如：
```shell
select * from table where name>'a' or address<'b'
```
mysql会将 name>'a' 的id进行排序，然后将 address<'b' 的id排序，最后将二者合并进行回表。

当满足索引合并的条件时也不一定会执行，仍然取决于优化器的判断。但当进行了索引合并，会在执行计划的extra中体现出来：Using intersect(...)、Using union(...)、Using sort_union


其实完全没有必要进行索引合并，只需建立联合索引就可以更高效的进行查询。