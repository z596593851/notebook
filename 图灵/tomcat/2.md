# Tomcat的io模型
## 五种io模型
![[Pasted image 20220601233543.png]]

io分为两个阶段，以read为例：一是读线程发起read请求后，读线程会从用户态切换到内核态等待内核态将数据准备好；二是内核态将数据准备好后，将数据拷贝到用户态。

阻塞与否指的是第一阶段，同步与否指的是第二阶段：

- bio会在内核态数据主备好前一直阻塞，而nio会不断检查内核数据是否准备好，如没有，则继续向下执行，不会阻塞；
- bio、nio在第二阶段内核态将数据准备好且将数据拷贝到用户态后，会通知读线程，这时读线程才会将获取到的数据返回，所以是同步的；而aio第二阶段数据准备好后也不会通知读线程，而是回调之前传入的回调函数，所以是异步的。
- nio在第一阶段只会监听一种事件，如accept，而io多路复用会使用selector监听所有时间，如accpet、read、write。

bio是同步阻塞io，nio是同步非阻塞io，aio是异步非阻塞io

通俗的解释：阻塞指的是，server尝试read时，如果client没有准备好要写的数据，server也会阻塞等待数据；而非阻塞是，server尝试read但是发现client没有准备好，就会继续执行而不会阻塞。
同步指的是，如果server尝试read并且client准备好了数据，则server需要在主线程同步处理读到的数据；异步是server不需要在主线程处理数据，而是异步回调之前传入的回调函数，类似于消息队列接收消息。

一句话总结：bio一次只能处理一个事件，处理时是阻塞的，服务端一个线程只能和客户端一个线程交互（因为和前一个客户端交互时是阻塞的，无法处理其他客户端的请求）；面向流，必须按顺序处理。
nio一次只能处理一个事件，处理时是非阻塞的，处理多个事件时需要手动依次轮询（accept、read、write依次轮询，即使没有read、write事件发生也得轮询）；面向缓冲区，可以不按顺序处理。
io多路复用一次可以处理多个事件，处理时是非阻塞的，处理多个事件时通过selector轮询（accept、read、write哪个发生了哪个才会通知selector，selector在下次轮询时会获取相应事件，而不用挨个轮询所有事件）。

Accept和Read事件注册完以后就不注销了，而Write事件注册完并且写完数据后要注销。一般只有客户端要给服务端发送数据时，注册op_write事件，发送完后再注销调op_write事件。因为如果不注销的话，写缓冲区只要有一点空闲空间，即可写状态，会不断使得selector触发isWritable()，使得cpu空转，写缓冲区恰恰常有空闲区；而读缓冲区一般都是空的，不会触发isReadble，所以不用注销。
```java
Iterator<SelectionKey> iterator = selectionKeys.iterator();  
while (iterator.hasNext()) {
	SelectionKey key = iterator.next();  
	iterator.remove();
	if (key.isReadable()) {   
		//读操作 
	}
	if (key.isWritable()) {
		//写操作
		channel.write(buffers);
		//注销写事件
		key.interestOps(key.interestOps() & ~SelectionKey.OP_WRITE);
	}
}
```

## tomcat支持的io模型
![[Pasted image 20220606211419.png]]

## tomcat如何选择合适的io模型
NIO在绝大多数情况下都是够用的。如果web应用使用了TLS加密传输，而且对性能要求极高，可以使用APR，用C实现，性能比java高，但是需要手动装类库。如果tomcat跑在windows平台上，可以使用AIO，因为windows的AIO比linux的完善，linux基于epoll实现，性能与nio持平，而windows不开源。

# Tomcat Endpoint的线程模型
## NioEndpoint
单reactor+线程池
![[Pasted image 20220606213228.png]]

多reactor（主从）
![[Pasted image 20220606213328.png]]

tomcat使用的是第二种
![[Pasted image 20220609232940.png]]
LimitLatch 是连接控制器，它负责控制最大连接数，NIO 模式下默认是 10000(tomcat9中8192)，当连接数到达最大时阻塞线程，直到后续组件处理完一个 连接后将连接数减 1。注意到达最大连接数后操作系统底层还是会接收客户端连接， 但用户层已经不再接收。

Acceptor 跑在一个单独的线程里，它在一个死循环里调用 accept 方法来接收 新连接，一旦有新的连接请求到来，accept() 方法返回获得 SocketChannel 对象，然后将 SocketChannel 对象封装在一个 PollerEvent 对象中，并将PollerEvent 对象压入 Poller 的 SynchronizedQueue 里，这是个典型的生产者 - 消费者 模式，Acceptor 与 Poller 线程之间通过 SynchronizedQueue 通信。

Poller 的本质是一个 Selector，也跑在单独线程里。Poller 在内部维护一个 Channel 数组，它在一个死循环里不断检测 Channel 的数据就绪状态，一旦有 Channel 可读，就生成一个 SocketProcessor 任务对象扔给 Executor 去处理。
![[Pasted image 20220609234522.png]]
(难道不是线程池在消费poller吗，像kafka那样)

# Tomcat的设计精髓
## 对线程池的扩展
![[Pasted image 20220606215836.png]]
tomcat可以指定核心线程和最大线程的大小，并且可以预先启动核心线程。但是jdk的线程池在线程数达到核心线程数时，再有请求到来，不会new新的线程，而是先进入等待队列；而tomcat则会先new新的线程，直到达到最大线程池大小，再进入等待队列。

tomcat线程池还自定义了拒绝策略，tomcat在线程总数达到最大值时，不会立即执行拒绝策略，而是再尝试向任务队列里添加任务，添加失败后再执行拒绝策略。

## 池技术
Acceptor当新连接到来时，会将 SocketChannel 对象封装在一个 PollerEvent 对象中，并将PollerEvent 对象压入 Poller 的 SynchronizedQueue 里。PollerEvent对象较大，每次新建和销毁都会有资源开销。为了减少新建和销毁的次数，从而减少GC次数，Tomcat利用SynchronizedStack来存放使用完的PollerEvent，并且把它分配给新的连接。SynchronizedStack内部维护了一个数组，实现了栈的push和pop接口，而且它本身只支持扩容不支持缩容。