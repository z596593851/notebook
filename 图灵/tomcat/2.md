# 五种io模型
![[Pasted image 20220601233543.png]]

io分为两个阶段，以read为例：一是读线程发起read请求后，读线程会从用户态切换到内核态等待内核态将数据准备好；二是内核态将数据准备好后，将数据拷贝到用户态。

阻塞与否指的是第一阶段，同步与否指的是第二阶段：

- bio会在内核态数据主备好前一直阻塞，而nio会不断检查内核数据是否准备好，如没有，则继续向下执行，不会阻塞；
- aio、nio在第二阶段内核态将数据准备好且将数据拷贝到用户态后，会通知读线程，这时读线程才会将获取到的数据返回，所以是同步的；而aio第二阶段数据准备好后也不会通知读线程，而是回调之前传入的回调函数，所以是异步的。
- nio在第一阶段只会监听一种时间，如accept，而io多路复用会使用selector监听所有时间，如accpet、read、write。

bio是同步阻塞io，nio是同步非阻塞io，aio是异步非阻塞io

## tomcat支持的io模型
![[Pasted image 20220606211419.png]]

## tomcat如何选择合适的io模型
NIO在绝大多数情况下都是够用的。如果web应用使用了TLS加密传输，而且对性能要求极高，可以使用APR，用C实现，性能比java高，但是需要手动装类库。如果tomcat跑在windows平台上，可以使用AIO，因为windows的AIO比linux的完善，linux基于epoll实现，性能与nio持平，而windows不开源。

# Tomcat Endpoint的线程模型
## NioEndpoint
单reactor+线程池
![[Pasted image 20220606213228.png]]

多reactor（主从）
![[Pasted image 20220606213328.png]]

tomcat使用的是第二种
![[Pasted image 20220609232940.png]]
LimitLatch 是连接控制器，它负责控制最大连接数，NIO 模式下默认是 10000(tomcat9中8192)，当连接数到达最大时阻塞线程，直到后续组件处理完一个 连接后将连接数减 1。注意到达最大连接数后操作系统底层还是会接收客户端连接， 但用户层已经不再接收。

Acceptor 跑在一个单独的线程里，它在一个死循环里调用 accept 方法来接收 新连接，一旦有新的连接请求到来，accept() 方法返回获得 SocketChannel 对象，然后将 SocketChannel 对象封装在一个 PollerEvent 对象中，并将PollerEvent 对象压入 Poller 的 SynchronizedQueue 里，这是个典型的生产者 - 消费者 模式，Acceptor 与 Poller 线程之间通过 SynchronizedQueue 通信。

Poller 的本质是一个 Selector，也跑在单独线程里。Poller 在内部维护一个 Channel 数组，它在一个死循环里不断检测 Channel 的数据就绪状态，一旦有 Channel 可读，就生成一个 SocketProcessor 任务对象扔给 Executor 去处理。
![[Pasted image 20220609234522.png]]
(难道不是线程池在消费poller吗，像kafka那样)

# Tomcat的设计精髓
## 对线程池的扩展
![[Pasted image 20220606215836.png]]
tomcat可以指定核心线程和最大线程的大小，并且可以预先启动核心线程。但是jdk的线程池在线程数达到核心线程数时，再有请求到来，不会new新的线程，而是先进入等待队列；而tomcat则会先new新的线程，直到达到最大线程池大小，再进入等待队列。

tomcat线程池还自定义了拒绝策略，tomcat在线程总数达到最大值时，不会立即执行拒绝策略，而是再尝试向任务队列里添加任务，添加失败后再执行拒绝策略。

## 池技术
Acceptor当新连接到来时，会将 SocketChannel 对象封装在一个 PollerEvent 对象中，并将PollerEvent 对象压入 Poller 的 SynchronizedQueue 里。PollerEvent对象较大，每次新建和销毁都会有资源开销。为了减少新建和销毁的次数，从而减少GC次数，Tomcat利用SynchronizedStack来存放使用完的PollerEvent，并且把它分配给新的连接。SynchronizedStack内部维护了一个数组，实现了栈的push和pop接口，而且它本身只支持扩容不支持缩容。